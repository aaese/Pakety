# -*- coding: utf-8 -*-
"""Untitled (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16cZjia5-Cns2YjLB9sPQzNwzLHeBlgzS
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from scipy import stats

"""## Задание 1"""

filename = 'anime.csv'
default_missing = pd._libs.parsers.STR_NA_VALUES
default_missing.add('-')
loaded_df = pd.read_csv(filename, thousands=',',na_values=default_missing)
df = loaded_df.copy()
s = pd.Series(df['Episodes'])
df['Episodes'] = pd.to_numeric(s, errors='coerce')

"""## Задание 2"""

df.head(10)

"""## Задание 3"""

df.dtypes

"""## Задание 4"""

df.columns = [str_.lower() for str_ in df.columns]

df.head(10)

"""## Задание 5"""

df.describe(percentiles=[.25,.75,.9])

"""## Задание 6"""

themes = [str(row).split(',') for row in df['theme']]
print(pd.DataFrame({'theme': [t for theme in themes for t in theme]}).theme.value_counts().sort_values())
geners = [str(row).split(',') for row in df['genre']]
print(pd.DataFrame({'genre': [t for gener in geners for t in gener]}).genre.value_counts().sort_values())
print(df.production.value_counts().sort_values())
print(df.source.value_counts().sort_values())

"""## Задание 7

Для большенства заданий был выбран путь удаления строк в котором были пропущенны данные т.к. колличество удаленных строк не вилико. Для анализа дат выпуска была созданна отдельная выборка в которой удалялось больше строк т.к. столбец дат имел наибольшее колличество пропусков.
"""

df.drop('airdate', inplace=True, axis=1)
df.dropna(how="any", inplace=True)
df.reset_index(drop=True, inplace=True)
s = pd.Series(df['episodes'], dtype="Int64")
df['episodes'] = pd.to_numeric(s)

def count(t):
  counts = []
  names = []
  for name,count in t.items():
      if len(counts)>0 and counts[-1] == count:
          names[len(counts) -1]+=', '+str(name)
      else:
          names.append(str(name))
          counts.append(count)
  return names, counts

"""## Задание 8"""

t= df.production.value_counts().sort_values()
names, counts = count(t)

print(f'Студия {names[-1]} выпустила {counts[-1]}, что является максимальным количеством аниме в датасете.')
plt.xticks(rotation=-90)
plt.bar(names,counts)

t= df.episodes.value_counts().sort_values()
names, counts = count(t)
print(f'Аниме с количесвом эпизодов {names[-1]} максимальное в датасете, и количество таких аниме {counts[-1]}')
plt.xticks(rotation=-90)
plt.bar(names,counts)

t= df.source.value_counts().sort_values()
names, counts = count(t)
print(f'Аниме с источником {names[-1]} максимальное в датасете, и количество таких аниме {counts[-1]}')
plt.xticks(rotation=-90)
plt.bar(names[-3:],counts[-3:])

t = pd.DataFrame({'index': [idx for idx,t in enumerate(themes) for t in range(len(t))],
                    'theme': [t for theme in themes for t in theme]}).theme.value_counts().sort_values()
names, counts = count(t)
print(f'Аниме с тема {names[-1]} максимальное в датасете, и количество таких аниме {counts[-1]}')
plt.xticks(rotation=-90)
plt.bar(names,counts)

date_df = loaded_df.copy()

date_df.dropna(how="any", inplace=True, subset = ['Airdate'])
t = pd.DataFrame({'airdate':[str(t).split(',')[1][1:] for t in date_df['Airdate']]}).airdate.value_counts().sort_values()
names, counts = count(t)
print(f'Аниме {names[-1]} года максимальное в датасете, и количество таких аниме {counts[-1]}')
plt.xticks(rotation=-90)
plt.bar(names,counts)

"""## Задание 9"""

t = df.groupby('production').mean()['rating'].sort_values()
names, counts = count(t)
print(f'Аниме компаний {names[-3:]} лучше в датасете, и их средний рейтинг соотвественно {counts[-3:]}')
plt.xticks(rotation=-90)
plt.bar(names,counts)

"""## Задание 10"""

t = df['rating'].astype(int).value_counts().sort_values()

names, counts = count(t)
print(f'Аниме c оценкой в промежутке [{names[-1]}-{int(names[-1])+1}) максимальное в датасете, и количество таких аниме {counts[-1]}')
plt.xticks(rotation=-90)
plt.bar(names,counts)

"""## Задание 11"""

df_11 = df.copy()
df_11['rating'] = df_11['rating'].astype(int)
themes = [str(row).split(',') for row in df['theme']]
des = pd.DataFrame({'rating': [df_11['rating'][idx] for idx,t in enumerate(themes) for t in range(len(t))],
                   'theme': [t for theme in themes for t in theme]}).groupby('theme')['rating'].describe().sort_values('min', ascending=False)
des[des['count'] > 20]

"""можем сделать вывод, что theme "Kids" и "Aniplex of America" имеют наивысший минимальный рейтинг возможно именно по этому они стали популярными"""

df_11 = df.copy()
df_11['rating'] = df_11['rating'].astype(int)
genres = [str(row).split(',') for row in df['genre']]
des = pd.DataFrame({'rating': [df_11['rating'][idx] for idx,t in enumerate(genres) for t in range(len(t))],
                   'genre': [t for genre in genres for t in genre]}).groupby('genre')['rating'].describe().sort_values('min', ascending=False)
des[des['count'] > 20]

"""можем сделать вывод, что жанр "Slice of Life" имеют наивысший минимальный рейтинг возможно именно по этому он стали популярными

## Задание 12
"""

v = df['voters']
r = df['rating']
plt.plot(v,r,'-')

"""Можно заметить, что чем больше голосов тем меньше плохих оценок. Из чего можно сделать вывод, что одной из причин популярности аниме является его качество.

## Задание 13
Гипотеза о том что у 2 компаний с самым большим количесвом выпушеного аниме одинаковый средний рейтинг.
"""

t= df.production.value_counts().sort_values()
names, counts = count(t)
s ,p =stats.ttest_ind(df[df['production'] == names[-1]]['rating'], df[df['production'] == names[-2]]['rating'], equal_var=False)
p

"""При стандартных уровнях значимости гипотиза отвергается.

Гипотеза о том что у 2 компаний с самым большим количесвом выпушеного аниме одинаковые распределения.
"""

s ,p =stats.ks_2samp(df[df['production'] == names[-1]]['rating'], df[df['production'] == names[-2]]['rating'])
p

"""При стандартных уровнях значимости гипотиза отвергается.

Гипотеза о том что рейтинги имеют нормальное распределение.
"""

stats.shapiro(df['rating'])

"""При стандартных уровнях значимости гипотиза отвергается."""

h = df['rating'].hist()
fig = h.get_figure()

"""Несколько общих выводов:

1) У данного датасета наблюдается 1 большой изьян это большое колличество пропусков в стролбце дат, что не дает нам возможности анализировать все данные по дате выпуска

2) Однако если дата выхода не является для нас ключевым показателем то датасет содержит очень мало "плохих" данных
"""



